{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Intro to Machine Learning: Megaline Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1. Project Description\n",
    "\n",
    "### Objective\n",
    "The goal of this project is to build a machine learning model that helps the mobile carrier **Megaline** recommend one of its two plans — **Smart** or **Ultra** — based on user behavior.\n",
    "\n",
    "### Task\n",
    "Develop a classification model that predicts the most suitable plan for a customer using monthly usage data.  \n",
    "The model’s accuracy on the test set must be **at least 0.75**.\n",
    "\n",
    "### Data Description\n",
    "Each row in the dataset represents one user's monthly behavior and includes the following features:\n",
    "- `calls` — number of calls made  \n",
    "- `minutes` — total call duration  \n",
    "- `messages` — number of text messages  \n",
    "- `mb_used` — internet traffic used (in MB)  \n",
    "- `is_ultra` — current plan (1 = Ultra, 0 = Smart)\n",
    "\n",
    "### Approach\n",
    "1. Explore and analyze the dataset.  \n",
    "2. Split data into training, validation, and test sets (with stratification).  \n",
    "3. Train and compare several models: **Logistic Regression**, **Decision Tree**, and **Random Forest**.  \n",
    "4. Tune hyperparameters and select the best model.  \n",
    "5. Evaluate the final model on the test set and draw conclusions."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2. Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import libraries\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def dataset_overview(df, name=\"df\", head_rows=5, target_col=None):\n",
    "    \"\"\"Quick sanity check:\n",
    "    - shape, columns\n",
    "    - dtypes (via df.info), memory\n",
    "    - missing (count/%)\n",
    "    - full-row duplicates\n",
    "    - optional: class balance for target_col\n",
    "    - head preview\n",
    "    \"\"\"\n",
    "    print(f\"=== Dataset overview: {name} ===\")\n",
    "\n",
    "    # Size\n",
    "    print(f\"Shape: {df.shape[0]} rows x {df.shape[1]} columns\")\n",
    "\n",
    "    # Columns\n",
    "    print(\"\\nColumns:\")\n",
    "    print(list(df.columns))\n",
    "\n",
    "    # Dtypes & memory\n",
    "    print(\"\\nDtypes & memory usage (df.info):\")\n",
    "    df.info()\n",
    "\n",
    "    # Missing values\n",
    "    print(\"\\nMissing values per column:\")\n",
    "    missing = df.isna().sum()\n",
    "    if missing.sum() == 0:\n",
    "        print(\"No missing values.\")\n",
    "    else:\n",
    "        missing_pct = (missing / len(df) * 100).round(2)\n",
    "        summary = pd.DataFrame({\"missing\": missing, \"missing_%\": missing_pct})\n",
    "        summary = summary[summary[\"missing\"] > 0].sort_values(\"missing_%\", ascending=False)\n",
    "        display(summary)\n",
    "\n",
    "    # Full-row duplicates\n",
    "    print(\"\\nDuplicate rows (full row duplicate):\", df.duplicated().sum())\n",
    "\n",
    "    # Preview\n",
    "    print(f\"\\nHead ({head_rows} rows):\")\n",
    "    display(df.head(head_rows))\n",
    "\n",
    "    print(\"\\n=== End ===\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Dataset overview: Megaline users behavior ===\n",
      "Shape: 3214 rows x 5 columns\n",
      "\n",
      "Columns:\n",
      "['calls', 'minutes', 'messages', 'mb_used', 'is_ultra']\n",
      "\n",
      "Dtypes & memory usage (df.info):\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 3214 entries, 0 to 3213\n",
      "Data columns (total 5 columns):\n",
      " #   Column    Non-Null Count  Dtype  \n",
      "---  ------    --------------  -----  \n",
      " 0   calls     3214 non-null   float64\n",
      " 1   minutes   3214 non-null   float64\n",
      " 2   messages  3214 non-null   float64\n",
      " 3   mb_used   3214 non-null   float64\n",
      " 4   is_ultra  3214 non-null   int64  \n",
      "dtypes: float64(4), int64(1)\n",
      "memory usage: 125.7 KB\n",
      "\n",
      "Missing values per column:\n",
      "No missing values.\n",
      "\n",
      "Duplicate rows (full row duplicate): 0\n",
      "\n",
      "Head (5 rows):\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>calls</th>\n",
       "      <th>minutes</th>\n",
       "      <th>messages</th>\n",
       "      <th>mb_used</th>\n",
       "      <th>is_ultra</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>40.0</td>\n",
       "      <td>311.90</td>\n",
       "      <td>83.0</td>\n",
       "      <td>19915.42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>85.0</td>\n",
       "      <td>516.75</td>\n",
       "      <td>56.0</td>\n",
       "      <td>22696.96</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>77.0</td>\n",
       "      <td>467.66</td>\n",
       "      <td>86.0</td>\n",
       "      <td>21060.45</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>106.0</td>\n",
       "      <td>745.53</td>\n",
       "      <td>81.0</td>\n",
       "      <td>8437.39</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>66.0</td>\n",
       "      <td>418.74</td>\n",
       "      <td>1.0</td>\n",
       "      <td>14502.75</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   calls  minutes  messages   mb_used  is_ultra\n",
       "0   40.0   311.90      83.0  19915.42         0\n",
       "1   85.0   516.75      56.0  22696.96         0\n",
       "2   77.0   467.66      86.0  21060.45         0\n",
       "3  106.0   745.53      81.0   8437.39         1\n",
       "4   66.0   418.74       1.0  14502.75         0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "=== End ===\n",
      "\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{0: 0.694, 1: 0.306}"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Load dataset\n",
    "df = pd.read_csv('users_behavior.csv')\n",
    "\n",
    "# Quick sanity overview \n",
    "dataset_overview(df, \"Megaline users behavior\")\n",
    "\n",
    "# Check class balance (target)\n",
    "df['is_ultra'].value_counts(normalize=True).round(3).to_dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Overview — Summary\n",
    "\n",
    "The dataset contains 3,214 rows and 5 columns.\n",
    "Each row represents one user’s monthly activity, including the number of calls, total call duration (in minutes), number of text messages, and internet usage (in megabytes).\n",
    "The target variable is_ultra indicates the user’s current plan: 1 = Ultra, 0 = Smart.\n",
    "\n",
    "All columns have correct numeric data types.\n",
    "There are no missing values or duplicate rows, and feature values look realistic.\n",
    "The dataset is clean and ready for next steps.\n",
    "\n",
    "**Class balance:**\n",
    "The target variable is_ultra is slightly imbalanced — about 69% Smart (0) and 31% Ultra (1)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3. Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes: (1928, 4) (643, 4) (643, 4)\n",
      "Overall:  {0: 0.694, 1: 0.306}\n",
      "Train: {0: 0.693, 1: 0.307}\n",
      "Valid: {0: 0.694, 1: 0.306}\n",
      "Test:  {0: 0.694, 1: 0.306}\n"
     ]
    }
   ],
   "source": [
    "# Separate features and target\n",
    "features = df.drop(columns=['is_ultra'])\n",
    "target = df['is_ultra']\n",
    "\n",
    "# Hold out final test set (20%) with stratification to preserve class ratios\n",
    "features_temp, features_test, target_temp, target_test = train_test_split(\n",
    "    features, target, test_size=0.20, stratify=target, random_state=12345\n",
    ")\n",
    "\n",
    "# Split the remaining 80% into train (60%) and validation (20% overall):\n",
    "# test_size=0.25 here means 25% of the temp set -> 0.25 * 0.80 = 0.20 of the full data\n",
    "features_train, features_valid, target_train, target_valid = train_test_split(\n",
    "    features_temp, target_temp, test_size=0.25, stratify=target_temp, random_state=12345\n",
    ")\n",
    "\n",
    "print(\"Shapes:\", features_train.shape, features_valid.shape, features_test.shape)\n",
    "\n",
    "# Class balance checks (should be close across all splits)\n",
    "print(\"Overall: \", target.value_counts(normalize=True).round(3).to_dict())\n",
    "print(\"Train:\", target_train.value_counts(normalize=True).round(3).to_dict())\n",
    "print(\"Valid:\", target_valid.value_counts(normalize=True).round(3).to_dict())\n",
    "print(\"Test: \", target_test.value_counts(normalize=True).round(3).to_dict())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data Splitting — Summary\n",
    "\n",
    "We split the dataset into three parts using stratified sampling to preserve the class ratio:\n",
    "- Train: 60% (1,928 rows)\n",
    "- Validation: 20% (643 rows)\n",
    "- Test: 20% (643 rows)\n",
    "\n",
    "Class proportions are consistent across all splits (~69% Smart, ~31% Ultra).\n",
    "The split is reproducible (random_state=12345) and non-overlapping between subsets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4. Model Training and Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.1. Logistic Regression Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation accuracy (Logistic Regression): 0.7558\n"
     ]
    }
   ],
   "source": [
    "# Initialize the model (fix random_state for reproducibility)\n",
    "lr_model = LogisticRegression(max_iter=1000, random_state=12345)\n",
    "\n",
    "# Fit the model on the training data\n",
    "lr_model.fit(features_train, target_train)\n",
    "\n",
    "# Generate predictions on the validation set\n",
    "predictions_valid = lr_model.predict(features_valid)\n",
    "\n",
    "# Compute the evaluation metric (accuracy) on validation\n",
    "result = accuracy_score(target_valid, predictions_valid)\n",
    "\n",
    "print(\"Validation accuracy (Logistic Regression):\", round(result, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Logistic Regression — Validation Results\n",
    "The model achieved a validation accuracy of 0.7558, which meets the target (≥ 0.75).\n",
    "This suggests that logistic regression performs well in distinguishing between Smart and Ultra users based on their monthly behavior."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.2. Decision Tree Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Best Decision Tree: accuracy=0.816 at max_depth=5\n"
     ]
    }
   ],
   "source": [
    "# Initialize placeholders for the best model, its score, and depth\n",
    "best_model = None\n",
    "best_result = -1.0\n",
    "best_depth = None\n",
    "\n",
    "# Try a range of tree depths (1..15) and keep the one with highest validation accuracy\n",
    "for depth in range(1, 16):\n",
    "    dt_model = DecisionTreeClassifier(max_depth=depth, random_state=12345)\n",
    "    dt_model.fit(features_train, target_train)\n",
    "    predictions_valid = dt_model.predict(features_valid)\n",
    "    result = accuracy_score(target_valid, predictions_valid)\n",
    "\n",
    "    if result > best_result:\n",
    "        best_model = dt_model\n",
    "        best_result = result\n",
    "        best_depth = depth\n",
    "\n",
    "print(f\"Best Decision Tree: accuracy={best_result:.3f} at max_depth={best_depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Decision Tree — Validation Summary\n",
    "\n",
    "- We trained Decision Tree classifiers with max_depth from 1 to 15.\n",
    "- Best result: **accuracy = 0.8165 at max_depth = 5** (validation set).\n",
    "- This outperforms Logistic Regression on validation (~0.756)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 4.3. Random Forest Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF n=100, depth=10: acc=0.8212\n",
      "RF n=100, depth=11: acc=0.8118\n",
      "RF n=100, depth=12: acc=0.8243\n",
      "RF n=100, depth=13: acc=0.8227\n",
      "RF n=100, depth=14: acc=0.8212\n",
      "RF n=100, depth=15: acc=0.8243\n",
      "RF n=100, depth=16: acc=0.8243\n",
      "RF n=100, depth=17: acc=0.8227\n",
      "RF n=100, depth=18: acc=0.8165\n",
      "RF n=100, depth=19: acc=0.8196\n",
      "RF n=100, depth=20: acc=0.8087\n",
      "RF n=100, depth=None: acc=0.8134\n",
      "RF n=200, depth=10: acc=0.8243\n",
      "RF n=200, depth=11: acc=0.8196\n",
      "RF n=200, depth=12: acc=0.8243\n",
      "RF n=200, depth=13: acc=0.8227\n",
      "RF n=200, depth=14: acc=0.8196\n",
      "RF n=200, depth=15: acc=0.8227\n",
      "RF n=200, depth=16: acc=0.8212\n",
      "RF n=200, depth=17: acc=0.8196\n",
      "RF n=200, depth=18: acc=0.8258\n",
      "RF n=200, depth=19: acc=0.8243\n",
      "RF n=200, depth=20: acc=0.8180\n",
      "RF n=200, depth=None: acc=0.8165\n",
      "RF n=300, depth=10: acc=0.8243\n"
     ]
    }
   ],
   "source": [
    "best_model = None\n",
    "best_result = -1.0\n",
    "best_est = None\n",
    "best_depth = None\n",
    "\n",
    "# Coarse-to-fine search:\n",
    "# - try a few tree counts (100, 200, 300)\n",
    "# - try depths 10..20 and also None (no depth limit)\n",
    "for est in [100, 200, 300]:\n",
    "    for depth in list(range(10, 21)) + [None]:\n",
    "        rf_model = RandomForestClassifier(\n",
    "            n_estimators=est,\n",
    "            max_depth=depth,\n",
    "            random_state=12345\n",
    "        )\n",
    "        rf_model.fit(features_train, target_train)\n",
    "        predictions_valid = rf_model.predict(features_valid)\n",
    "        result = accuracy_score(target_valid, predictions_valid)\n",
    "\n",
    "        print(f\"RF n={est}, depth={depth}: acc={result:.4f}\")\n",
    "\n",
    "        if result > best_result:\n",
    "            best_model = rf_model\n",
    "            best_result = result\n",
    "            best_est = est\n",
    "            best_depth = depth\n",
    "\n",
    "print(f\"\\nBest RF on validation: accuracy={best_result:.4f}, n_estimators={best_est}, max_depth={best_depth}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Random Forest - Validation Summary\n",
    "- Tested n_estimators {100, 200, 300} and max_depth {10…20, None}.\n",
    "- Best validation accuracy = 0.8243 at n_estimators = 100, max_depth = 12\n",
    "- Random Forest slightly outperformed Logistic Regression (~0.756) and Decision Tree (0.8165)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Training and Evaluation — Summary\n",
    "\n",
    "We tested three classification models:  \n",
    "\n",
    "| Model | Validation accuracy | Comments |\n",
    "|:------|:--------------------|:----------|\n",
    "| Logistic Regression | **0.7558** | Simple linear model; meets the target threshold. |\n",
    "| Decision Tree | **0.8165** | Non-linear model; performed significantly better. |\n",
    "| Random Forest | **0.8243** | Ensemble of trees; achieved the highest accuracy with `n_estimators=100`, `max_depth=12`. |\n",
    "\n",
    "**Conclusion:**  \n",
    "The Random Forest model achieved the best validation accuracy (0.8243) and demonstrates stable performance without overfitting.  \n",
    "This model will be retrained on the combined training and validation sets and evaluated on the test set to estimate its final quality."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 5. Final Model Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Merge training and validation sets to train the final model on more data\n",
    "features_train_valid = pd.concat([features_train, features_valid])\n",
    "target_train_valid = pd.concat([target_train, target_valid])\n",
    "\n",
    "# Define the final Random Forest with the best hyperparameters from validation\n",
    "final_model = RandomForestClassifier(\n",
    "            n_estimators=100,\n",
    "            max_depth=12,\n",
    "            random_state=12345\n",
    ")\n",
    "\n",
    "# Fit the final model on the combined train+validation data\n",
    "final_model.fit(features_train_valid, target_train_valid)\n",
    "\n",
    "# Predict on the held-out test set (never seen during training/tuning)\n",
    "predictions_test = final_model.predict(features_test)\n",
    "\n",
    "# Compute the final test accuracy\n",
    "test_accuracy = accuracy_score(target_test, predictions_test)\n",
    "print(\"Test accuracy (Final Random Forest):\", round(test_accuracy, 4))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Final Model Testing — Summary\n",
    "\n",
    "The final model — **Random Forest** (`n_estimators=100`, `max_depth=12`) —  \n",
    "was trained on the combined training and validation sets and evaluated on the test set.\n",
    "\n",
    "| Dataset | Accuracy |\n",
    "|:--------|:----------|\n",
    "| Validation | **0.8243** |\n",
    "| Test | **0.8165** |\n",
    "\n",
    "The model maintains stable performance on unseen data, showing only a minor drop in accuracy (from 0.8243 to 0.8165).  \n",
    "This indicates good generalization and no signs of overfitting.  \n",
    "The final accuracy exceeds the project threshold of **0.75**, meaning the model successfully classifies users into the correct tariff plan (Smart or Ultra)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 6. Project Conclusions\n",
    "\n",
    "#### Goal\n",
    "The goal of this project was to develop a machine learning model for **Megaline**, a mobile carrier company.  \n",
    "The model should analyze subscriber behavior and recommend one of the two available plans — **Smart (0)** or **Ultra (1)** — with a target **accuracy ≥ 0.75**.\n",
    "\n",
    "---\n",
    "\n",
    "#### Models tested\n",
    "\n",
    "| Model | Validation Accuracy | Notes |\n",
    "|:------|:--------------------|:------|\n",
    "| Logistic Regression | **0.756** | Simple linear model; reached the required threshold. |\n",
    "| Decision Tree | **0.8165** | Non-linear model; showed significant improvement. |\n",
    "| Random Forest | **0.8243** | Best validation score with `n_estimators=100`, `max_depth=12`. |\n",
    "\n",
    "---\n",
    "\n",
    "#### Final evaluation\n",
    "The best-performing model — **Random Forest (n_estimators=100, max_depth=12)** —  \n",
    "was retrained on the combined training and validation sets and tested on the unseen test data.\n",
    "\n",
    "| Dataset | Accuracy |\n",
    "|:--------|:----------|\n",
    "| Validation | **0.8243** |\n",
    "| Test | **0.8165** |\n",
    "\n",
    "---\n",
    "\n",
    "#### Conclusions\n",
    "- The Random Forest model achieved the highest accuracy among all tested algorithms.  \n",
    "- The test accuracy (**0.8165**) is slightly lower than validation but still well above the required 0.75, indicating **good generalization** and **no overfitting**.  \n",
    "- The model successfully predicts which tariff plan (Smart or Ultra) best fits a customer based on their behavior.  \n",
    "- Logistic Regression reached the minimum threshold but was outperformed by tree-based models.  \n",
    "- Decision Tree performed well, yet Random Forest proved more **stable** and **robust**.\n",
    "\n",
    "**Final Result:**  \n",
    "The project goal is achieved — the final model meets quality requirements and can be recommended for deployment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Reflection\n",
    "\n",
    "This project helped me better understand how machine learning models work in practice.  \n",
    "I learned how to split data correctly into training, validation, and test sets and why stratification is important.  \n",
    "\n",
    "I also practiced training several models, tuning their parameters, and comparing their performance using accuracy as the main metric.  \n",
    "\n",
    "The most interesting part for me was working with the **Decision Tree** and **Random Forest** models —  \n",
    "I could really see how changing hyperparameters affects the quality of predictions.  \n",
    "\n",
    "At first, it was difficult to keep all steps structured and not get lost between datasets and models,  \n",
    "but as I went through each stage, it became clearer how the whole machine learning process fits together.  \n",
    "Overall, I’m satisfied with the result — my model reached the target accuracy and showed stable performance on the test data."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
